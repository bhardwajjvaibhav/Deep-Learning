{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sOhPu_FFwMM5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('Shakespeare_data.csv')\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lIi3IDswvD8",
        "outputId": "b1198c73-510c-4d2a-9943-2b615b7977f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Dataline      Play  PlayerLinenumber ActSceneLine         Player  \\\n",
            "0         1  Henry IV               NaN          NaN            NaN   \n",
            "1         2  Henry IV               NaN          NaN            NaN   \n",
            "2         3  Henry IV               NaN          NaN            NaN   \n",
            "3         4  Henry IV               1.0        1.1.1  KING HENRY IV   \n",
            "4         5  Henry IV               1.0        1.1.2  KING HENRY IV   \n",
            "\n",
            "                                          PlayerLine  \n",
            "0                                              ACT I  \n",
            "1                       SCENE I. London. The palace.  \n",
            "2  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...  \n",
            "3             So shaken as we are, so wan with care,  \n",
            "4         Find we a time for frighted peace to pant,  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting text from the data\n",
        "text = []\n",
        "for i in data['PlayerLine']:\n",
        "    text.append(i)\n",
        "\n",
        "# lets see how the text is looking\n",
        "text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggtfWF2Pyltn",
        "outputId": "2e03139d-bb99-4702-8b1d-e6d485d70a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ACT I',\n",
              " 'SCENE I. London. The palace.',\n",
              " 'Enter KING HENRY, LORD JOHN OF LANCASTER, the EARL of WESTMORELAND, SIR WALTER BLUNT, and others',\n",
              " 'So shaken as we are, so wan with care,',\n",
              " 'Find we a time for frighted peace to pant,']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text Cleaning\n",
        "def clean_text(text):\n",
        "    # removing special characters like @, #, $, etc\n",
        "    pattern = re.compile('[^a-zA-z0-9\\s]')\n",
        "    text = re.sub(pattern,'',text)\n",
        "\n",
        "    # removing digits\n",
        "    pattern = re.compile('\\d+')\n",
        "    text = re.sub(pattern,'',text)\n",
        "\n",
        "    # converting text to lower case\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "texts = []\n",
        "for t in text:\n",
        "    new_text = clean_text(t)\n",
        "    texts.append(new_text)\n",
        "\n",
        "# cleaned text\n",
        "texts[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuRz1mvYypEt",
        "outputId": "bdd8f4f7-08c9-4305-de07-546aa0fdf90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['act i',\n",
              " 'scene i london the palace',\n",
              " 'enter king henry lord john of lancaster the earl of westmoreland sir walter blunt and others',\n",
              " 'so shaken as we are so wan with care',\n",
              " 'find we a time for frighted peace to pant']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "source": [
        "# lets take first 10000 words for the model training\n",
        "texts = texts[:10000]\n",
        "\n",
        "# using tensorflow tokenizer and\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "# generating text sequences, i.e. encoding the text\n",
        "text_sequences = tokenizer.texts_to_sequences(texts) # Remove np.array()\n",
        "print('Text -->>',texts[0])\n",
        "print('Embedding -->>',text_sequences[0])\n",
        "\n",
        "# padding the sequences\n",
        "Max_Sequence_Len = max([len(x) for x in text_sequences])\n",
        "text_sequences = pad_sequences(text_sequences,\n",
        "                               maxlen = Max_Sequence_Len, padding='pre') # pad_sequences expects a list\n",
        "\n",
        "print('Maximum Sequence Length -->>',Max_Sequence_Len)\n",
        "print('Text Sequence -->>\\n',text_sequences[0])\n",
        "print('Text Sequence Shape -->>',text_sequences.shape)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8S4UzjTy9v2",
        "outputId": "a062fe1e-9610-4ac4-f454-1549a75aa9cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text -->> act i\n",
            "Embedding -->> [455, 4]\n",
            "Maximum Sequence Length -->> 54\n",
            "Text Sequence -->>\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 455   4]\n",
            "Text Sequence Shape -->> (10000, 54)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting X and y from the data\n",
        "X, y = text_sequences[:, :-1], text_sequences[:,-1]\n",
        "print('First Input :',X[0])\n",
        "print('First Target :',y[0])\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# using one hot encoding on y\n",
        "total_words = len(word_index) + 1\n",
        "print('Total Number of Words:',total_words)\n",
        "\n",
        "y = to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# printing X and y shapes\n",
        "print('Input Shape :',X.shape)\n",
        "print('Target Shape :',y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDtpDPc9zQLI",
        "outputId": "c4de8d0a-6477-456e-8e1b-4a9cb932dadc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Input : [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 455]\n",
            "First Target : 4\n",
            "Total Number of Words: 7865\n",
            "Input Shape : (10000, 53)\n",
            "Target Shape : (10000, 7865)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(name=\"LSTM_Model\")\n",
        "\n",
        "# adding embedding layer\n",
        "model.add(Embedding(total_words,\n",
        "                    Max_Sequence_Len-1,\n",
        "                    input_length=Max_Sequence_Len-1))\n",
        "\n",
        "# adding a LSTM layer\n",
        "model.add(LSTM(512, return_sequences=False))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "#adding the final output activation with activation function of softmax\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# printing model summary\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "ouqcaOC9zT7w",
        "outputId": "d40fd59d-38bf-41e4-d920-6a5cf3dbcc24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"LSTM_Model\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LSTM_Model\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Training the LSTM model\n",
        "history = model.fit(X, y,\n",
        "                       epochs=50,\n",
        "                       verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayuNErEWzX24",
        "outputId": "4504e9e2-9a7b-407e-9924-1b5d954d21f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 677ms/step - accuracy: 0.0107 - loss: 8.2064\n",
            "Epoch 2/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 660ms/step - accuracy: 0.0196 - loss: 7.3656\n",
            "Epoch 3/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 660ms/step - accuracy: 0.0270 - loss: 7.0830\n",
            "Epoch 4/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 662ms/step - accuracy: 0.0276 - loss: 6.8596\n",
            "Epoch 5/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 653ms/step - accuracy: 0.0311 - loss: 6.5556\n",
            "Epoch 6/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 654ms/step - accuracy: 0.0384 - loss: 6.2501\n",
            "Epoch 7/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 649ms/step - accuracy: 0.0473 - loss: 5.8923\n",
            "Epoch 8/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 664ms/step - accuracy: 0.0657 - loss: 5.4536\n",
            "Epoch 9/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 668ms/step - accuracy: 0.0972 - loss: 5.0058\n",
            "Epoch 10/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 671ms/step - accuracy: 0.1351 - loss: 4.5055\n",
            "Epoch 11/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 670ms/step - accuracy: 0.1954 - loss: 4.0026\n",
            "Epoch 12/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 656ms/step - accuracy: 0.2580 - loss: 3.5209\n",
            "Epoch 13/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 662ms/step - accuracy: 0.3705 - loss: 3.0044\n",
            "Epoch 14/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 655ms/step - accuracy: 0.4586 - loss: 2.5237\n",
            "Epoch 15/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 666ms/step - accuracy: 0.5411 - loss: 2.1596\n",
            "Epoch 16/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 664ms/step - accuracy: 0.6196 - loss: 1.8169\n",
            "Epoch 17/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 672ms/step - accuracy: 0.6798 - loss: 1.5040\n",
            "Epoch 18/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 669ms/step - accuracy: 0.7410 - loss: 1.2662\n",
            "Epoch 19/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 658ms/step - accuracy: 0.7725 - loss: 1.0931\n",
            "Epoch 20/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 667ms/step - accuracy: 0.8186 - loss: 0.9073\n",
            "Epoch 21/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 654ms/step - accuracy: 0.8425 - loss: 0.8063\n",
            "Epoch 22/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 659ms/step - accuracy: 0.8643 - loss: 0.7130\n",
            "Epoch 23/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 652ms/step - accuracy: 0.8872 - loss: 0.5958\n",
            "Epoch 24/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 658ms/step - accuracy: 0.8940 - loss: 0.5384\n",
            "Epoch 25/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 655ms/step - accuracy: 0.8978 - loss: 0.5200\n",
            "Epoch 26/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 652ms/step - accuracy: 0.9109 - loss: 0.4475\n",
            "Epoch 27/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 663ms/step - accuracy: 0.9239 - loss: 0.4016\n",
            "Epoch 28/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 669ms/step - accuracy: 0.9297 - loss: 0.3658\n",
            "Epoch 29/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 663ms/step - accuracy: 0.9290 - loss: 0.3546\n",
            "Epoch 30/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 656ms/step - accuracy: 0.9289 - loss: 0.3322\n",
            "Epoch 31/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 648ms/step - accuracy: 0.9324 - loss: 0.3347\n",
            "Epoch 32/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 646ms/step - accuracy: 0.9373 - loss: 0.3032\n",
            "Epoch 33/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 660ms/step - accuracy: 0.9415 - loss: 0.2847\n",
            "Epoch 34/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 657ms/step - accuracy: 0.9418 - loss: 0.2789\n",
            "Epoch 35/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 659ms/step - accuracy: 0.9471 - loss: 0.2640\n",
            "Epoch 36/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 653ms/step - accuracy: 0.9407 - loss: 0.2725\n",
            "Epoch 37/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 668ms/step - accuracy: 0.9454 - loss: 0.2512\n",
            "Epoch 38/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 654ms/step - accuracy: 0.9464 - loss: 0.2507\n",
            "Epoch 39/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 653ms/step - accuracy: 0.9514 - loss: 0.2300\n",
            "Epoch 40/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 640ms/step - accuracy: 0.9476 - loss: 0.2351\n",
            "Epoch 41/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 656ms/step - accuracy: 0.9514 - loss: 0.2180\n",
            "Epoch 42/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 654ms/step - accuracy: 0.9522 - loss: 0.2080\n",
            "Epoch 43/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 654ms/step - accuracy: 0.9529 - loss: 0.2141\n",
            "Epoch 44/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 660ms/step - accuracy: 0.9524 - loss: 0.2067\n",
            "Epoch 45/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 641ms/step - accuracy: 0.9548 - loss: 0.2041\n",
            "Epoch 46/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 650ms/step - accuracy: 0.9534 - loss: 0.2139\n",
            "Epoch 47/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 643ms/step - accuracy: 0.9444 - loss: 0.2343\n",
            "Epoch 48/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 653ms/step - accuracy: 0.9530 - loss: 0.2058\n",
            "Epoch 49/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 663ms/step - accuracy: 0.9550 - loss: 0.1938\n",
            "Epoch 50/50\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 662ms/step - accuracy: 0.9583 - loss: 0.1818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def autoCompletations(text, model):\n",
        "    # Tokenization and Text vectorization\n",
        "    text_sequences = np.array(tokenizer.texts_to_sequences([text]))\n",
        "    # Pre-padding\n",
        "    testing = pad_sequences(text_sequences, maxlen = Max_Sequence_Len-1, padding='pre')\n",
        "    # Prediction\n",
        "    y_pred_test = np.argmax(model.predict(testing,verbose=0))\n",
        "\n",
        "    predicted_word = ''\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == y_pred_test:\n",
        "            predicted_word = word\n",
        "            break\n",
        "    text += \" \" + predicted_word + '.'\n",
        "    return text\n",
        "\n",
        "complete_sentence = autoCompletations('I have seen this', model)\n",
        "complete_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "0DQqQmFSzcz6",
        "outputId": "6c1021d8-f618-47f6-afee-0c4f1bd74198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have seen this cause.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(text, new_words):\n",
        "    for _ in range(new_words):\n",
        "        text = autoCompletations(text, model)[:-1]\n",
        "    return text\n",
        "\n",
        "generated_text = generate_text('I have seen', 5)\n",
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kVa4Fgd20kST",
        "outputId": "8738f43a-16ec-45ca-880a-b3c4fa031a3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I have seen him now on me now'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the model\n",
        "model.save('sentence_completion.h5')\n",
        "\n",
        "# saving the tokenizer\n",
        "filename = 'tokenizer.pkl'\n",
        "pickle.dump(tokenizer, open(filename, 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ISsH0ho0lE_",
        "outputId": "952cb569-97c3-427b-c9bc-c4a2c9ff92a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}